# Fine-tuning dependencies for Korean Legal LLM
# Base model: kakaocorp/kanana-nano-2.1b-instruct
# Method: QLoRA (Quantized Low-Rank Adaptation)

# Core transformers and datasets
transformers>=4.57.5
datasets>=4.5.0

# Fine-tuning and optimization
peft>=0.18.1
trl>=0.12.0
bitsandbytes>=0.45.0
accelerate>=1.12.0

# Deep learning framework
torch>=2.9.1

# Optional: For model conversion and deployment
# llama-cpp-python>=0.3.16
